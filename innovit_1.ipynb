{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c56c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'imp'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Download YOLOv11n model weights\n",
    "print(\"Downloading YOLOv11n model weights...\")\n",
    "model_url = \"https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov11n.pt\"\n",
    "model_path = os.path.expanduser(\"~/.local/share/Ultralytics/\") if os.name != 'nt' else os.path.join(os.path.expandvars(\"%APPDATA%\"), \"Ultralytics\")\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "model_file = os.path.join(model_path, \"yolov11n.pt\")\n",
    "\n",
    "if not os.path.exists(model_file):\n",
    "    try:\n",
    "        print(f\"Downloading to {model_file}...\")\n",
    "        urllib.request.urlretrieve(model_url, model_file)\n",
    "        print(\"âœ“ Model downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Could not auto-download model. Error: {e}\")\n",
    "        print(\"Will attempt to download during training...\")\n",
    "else:\n",
    "    print(f\"âœ“ Model already exists at {model_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda1ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['ultralytics', 'albumentations', 'opencv-python', 'numpy', 'pillow', 'pyyaml', 'torch', 'scikit-learn', 'matplotlib', 'seaborn']\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.split('-')[0])\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "base_path = r\"C:\\Users\\praha\\Downloads\\archive (4)\\innovit_.ipynb\\SBVPI_SIP\"\n",
    "training_images_path = os.path.join(base_path, \"Training\", \"Images\")\n",
    "training_masks_path = os.path.join(base_path, \"Training\", \"Masks\")\n",
    "synthetic_images_path = os.path.join(base_path, \"Training\", \"Synthetic_Images\")\n",
    "synthetic_masks_path = os.path.join(base_path, \"Training\", \"Synthetic_Masks\")\n",
    "\n",
    "# Create synthetic directories if they don't exist\n",
    "os.makedirs(synthetic_images_path, exist_ok=True)\n",
    "os.makedirs(synthetic_masks_path, exist_ok=True)\n",
    "\n",
    "# Define augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.Rotate(limit=45, p=0.7),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.GaussianBlur(blur_limit=3, p=0.3),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
    "    A.Affine(shear=(-8, 8), p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.3),\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "print(\"Generating 100 synthetic images from existing dataset...\")\n",
    "print(f\"Source images: {training_images_path}\")\n",
    "print(f\"Source masks: {training_masks_path}\")\n",
    "\n",
    "# Get list of original images\n",
    "image_files = sorted([f for f in os.listdir(training_images_path) if f.endswith('.png')])\n",
    "num_images = len(image_files)\n",
    "print(f\"Found {num_images} original images\")\n",
    "\n",
    "# Generate 100 synthetic images (1 augmentation per original image)\n",
    "synthetic_count = 0\n",
    "for i, image_file in enumerate(tqdm(image_files, desc=\"Creating synthetic data\")):\n",
    "    if synthetic_count >= 100:\n",
    "        break\n",
    "    \n",
    "    # Read original image and mask\n",
    "    image_path = os.path.join(training_images_path, image_file)\n",
    "    mask_path = os.path.join(training_masks_path, image_file)\n",
    "    \n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"Warning: Mask not found for {image_file}\")\n",
    "        continue\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path)\n",
    "    \n",
    "    if image is None or mask is None:\n",
    "        print(f\"Error reading {image_file}\")\n",
    "        continue\n",
    "    \n",
    "    # Apply augmentations\n",
    "    for aug_num in range(1):  # 1 augmentation per image\n",
    "        augmented = transform(image=image, mask=mask)\n",
    "        aug_image = augmented['image']\n",
    "        aug_mask = augmented['mask']\n",
    "        \n",
    "        # Save synthetic image and mask\n",
    "        synthetic_image_name = f\"synthetic_{synthetic_count:03d}_{image_file}\"\n",
    "        synthetic_image_path = os.path.join(synthetic_images_path, synthetic_image_name)\n",
    "        synthetic_mask_path = os.path.join(synthetic_masks_path, synthetic_image_name)\n",
    "        \n",
    "        cv2.imwrite(synthetic_image_path, aug_image)\n",
    "        cv2.imwrite(synthetic_mask_path, aug_mask)\n",
    "        \n",
    "        synthetic_count += 1\n",
    "\n",
    "print(f\"\\nâœ“ Successfully created {synthetic_count} synthetic images\")\n",
    "print(f\"Synthetic images saved to: {synthetic_images_path}\")\n",
    "print(f\"Synthetic masks saved to: {synthetic_masks_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create YOLO dataset structure\n",
    "yolo_dataset_path = os.path.join(base_path, \"yolo_dataset\")\n",
    "os.makedirs(yolo_dataset_path, exist_ok=True)\n",
    "\n",
    "# Create directory structure\n",
    "train_images_dir = os.path.join(yolo_dataset_path, \"images\", \"train\")\n",
    "train_labels_dir = os.path.join(yolo_dataset_path, \"labels\", \"train\")\n",
    "val_images_dir = os.path.join(yolo_dataset_path, \"images\", \"val\")\n",
    "val_labels_dir = os.path.join(yolo_dataset_path, \"labels\", \"val\")\n",
    "\n",
    "for dir_path in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Combine original and synthetic images\n",
    "all_images = []\n",
    "all_masks = []\n",
    "\n",
    "# Add original images\n",
    "print(\"\\nPreparing dataset...\")\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(training_images_path, img_file)\n",
    "    mask_path = os.path.join(training_masks_path, img_file)\n",
    "    all_images.append(img_path)\n",
    "    all_masks.append(mask_path)\n",
    "\n",
    "# Add synthetic images\n",
    "synthetic_files = sorted([f for f in os.listdir(synthetic_images_path) if f.endswith('.png')])\n",
    "for syn_file in synthetic_files:\n",
    "    syn_img_path = os.path.join(synthetic_images_path, syn_file)\n",
    "    syn_mask_path = os.path.join(synthetic_masks_path, syn_file)\n",
    "    all_images.append(syn_img_path)\n",
    "    all_masks.append(syn_mask_path)\n",
    "\n",
    "print(f\"Total images (original + synthetic): {len(all_images)}\")\n",
    "\n",
    "# Split into train and validation (80-20 split)\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(\n",
    "    all_images, all_masks, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training images: {len(train_images)}\")\n",
    "print(f\"Validation images: {len(val_images)}\")\n",
    "\n",
    "# Copy images to YOLO directory structure\n",
    "print(\"\\nCopying files to YOLO dataset structure...\")\n",
    "for src_img, src_mask in tqdm(zip(train_images, train_masks), total=len(train_images), desc=\"Training data\"):\n",
    "    filename = os.path.basename(src_img)\n",
    "    shutil.copy(src_img, os.path.join(train_images_dir, filename))\n",
    "\n",
    "for src_img, src_mask in tqdm(zip(val_images, val_masks), total=len(val_images), desc=\"Validation data\"):\n",
    "    filename = os.path.basename(src_img)\n",
    "    shutil.copy(src_img, os.path.join(val_images_dir, filename))\n",
    "\n",
    "print(f\"\\nâœ“ Dataset prepared successfully!\")\n",
    "print(f\"YOLO dataset path: {yolo_dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffdf7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING LABELS FROM MASKS FOR TRAINING AND VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def create_yolo_labels_from_masks(images_list, masks_list, labels_dir):\n",
    "    \"\"\"Create YOLO format labels from mask files\"\"\"\n",
    "    created_count = 0\n",
    "    \n",
    "    for img_path, mask_path in tqdm(zip(images_list, masks_list), total=len(images_list), desc=\"Creating labels\"):\n",
    "        if not os.path.exists(mask_path):\n",
    "            continue\n",
    "            \n",
    "        # Create label file path\n",
    "        img_basename = os.path.basename(img_path)\n",
    "        label_file = os.path.splitext(img_basename)[0] + '.txt'\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        \n",
    "        # Skip if already exists\n",
    "        if os.path.exists(label_path):\n",
    "            continue\n",
    "        \n",
    "        # Read mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            # Create empty label if mask can't be read\n",
    "            open(label_path, 'a').close()\n",
    "            created_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Find contours in mask\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        with open(label_path, 'w') as f:\n",
    "            if len(contours) > 0:\n",
    "                img_h, img_w = mask.shape[:2]\n",
    "                \n",
    "                for contour in contours:\n",
    "                    # Get bounding box\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    \n",
    "                    # Skip very small boxes\n",
    "                    if w < 5 or h < 5:\n",
    "                        continue\n",
    "                    \n",
    "                    # Convert to YOLO format (normalized center coordinates and width/height)\n",
    "                    x_center = (x + w/2) / img_w\n",
    "                    y_center = (y + h/2) / img_h\n",
    "                    box_w = w / img_w\n",
    "                    box_h = h / img_h\n",
    "                    \n",
    "                    # Clamp to [0, 1]\n",
    "                    x_center = max(0, min(1, x_center))\n",
    "                    y_center = max(0, min(1, y_center))\n",
    "                    box_w = max(0, min(1, box_w))\n",
    "                    box_h = max(0, min(1, box_h))\n",
    "                    \n",
    "                    # Write label (class_id x_center y_center width height)\n",
    "                    f.write(f\"0 {x_center:.6f} {y_center:.6f} {box_w:.6f} {box_h:.6f}\\n\")\n",
    "            # If no contours, create empty file (image has no objects)\n",
    "        \n",
    "        created_count += 1\n",
    "    \n",
    "    return created_count\n",
    "\n",
    "# Create training labels\n",
    "print(f\"\\nâœ“ Creating training labels ({len(train_images)} images)...\")\n",
    "train_labels_created = create_yolo_labels_from_masks(train_images, train_masks, train_labels_dir)\n",
    "print(f\"  Created {train_labels_created} training labels\")\n",
    "\n",
    "# Create validation labels\n",
    "print(f\"\\nâœ“ Creating validation labels ({len(val_images)} images)...\")\n",
    "val_labels_created = create_yolo_labels_from_masks(val_images, val_masks, val_labels_dir)\n",
    "print(f\"  Created {val_labels_created} validation labels\")\n",
    "\n",
    "# Verify labels exist\n",
    "train_label_files = len([f for f in os.listdir(train_labels_dir) if f.endswith('.txt')])\n",
    "val_label_files = len([f for f in os.listdir(val_labels_dir) if f.endswith('.txt')])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LABEL CREATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training: {train_label_files} labels for {len(train_images)} images\")\n",
    "print(f\"Validation: {val_label_files} labels for {len(val_images)} images\")\n",
    "\n",
    "if train_label_files > 0 and val_label_files > 0:\n",
    "    print(\"âœ“ Labels created successfully!\")\n",
    "else:\n",
    "    print(\"âš ï¸  WARNING: Some labels may be missing!\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "# Create YOLO dataset configuration file\n",
    "dataset_config = {\n",
    "    'path': yolo_dataset_path,\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'nc': 1,  # number of classes (change based on your needs)\n",
    "    'names': ['object']  # class names (modify as needed)\n",
    "}\n",
    "\n",
    "config_path = os.path.join(yolo_dataset_path, 'data.yaml')\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(dataset_config, f)\n",
    "\n",
    "print(f\"Dataset configuration saved to: {config_path}\")\n",
    "print(\"\\nStarting YOLOv8 training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize YOLOv8 model (more stable than v11)\n",
    "print(\"Initializing YOLOv8n model...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "print(\"âœ“ Model loaded successfully\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nStarting training...\")\n",
    "results = model.train(\n",
    "    data=config_path,\n",
    "    epochs=50,  # Increase epochs for better learning\n",
    "    imgsz=416,  # Image size\n",
    "    batch=8,  # Smaller batch for better gradient updates\n",
    "    patience=15,  # Early stopping patience\n",
    "    device=0 if torch.cuda.is_available() else 'cpu',\n",
    "    project='runs/detect',  # Project directory\n",
    "    name='yolov8_training',  # Run name\n",
    "    save=True,\n",
    "    exist_ok=True,  # Allow retraining\n",
    "    verbose=True,\n",
    "    lr0=0.001,  # Higher initial learning rate\n",
    "    lrf=0.01,  # Final learning rate\n",
    "    momentum=0.9,  # Momentum\n",
    "    weight_decay=0.0005,  # Weight decay\n",
    "    warmup_epochs=3,  # Warmup epochs\n",
    "    flipud=0.5,  # Random vertical flip\n",
    "    fliplr=0.5,  # Random horizontal flip\n",
    "    mosaic=1.0,  # Mosaic augmentation\n",
    "    mixup=0.1,  # Mixup augmentation\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ“ Training completed!\")\n",
    "print(f\"Best model: {results.save_dir}/weights/best.pt\")\n",
    "print(f\"Last model: {results.save_dir}/weights/last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "# Reload the trained model\n",
    "model_path = r'C:\\Users\\praha\\Downloads\\archive (4)\\innovit_.ipynb\\runs\\detect\\runs\\detect\\yolov8_training\\weights\\best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ Model Training Successfully Completed!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nModel Path: {model_path}\")\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  â€¢ Initial Images: 99\")\n",
    "print(f\"  â€¢ Synthetic Images: 99\")\n",
    "print(f\"  â€¢ Total Training Images: 198\")\n",
    "print(f\"  â€¢ Training Set: 158 images (80%)\")\n",
    "print(f\"  â€¢ Validation Set: 40 images (20%)\")\n",
    "print(f\"  â€¢ Epochs: 20\")\n",
    "print(f\"  â€¢ Image Size: 416x416\")\n",
    "print(f\"  â€¢ Batch Size: 16\")\n",
    "\n",
    "# Basic model info\n",
    "print(f\"\\nModel Information:\")\n",
    "print(f\"  â€¢ Model: YOLOv8 Nano\")\n",
    "print(f\"  â€¢ Architecture: 73 layers\")\n",
    "print(f\"  â€¢ Parameters: 3,005,843\")\n",
    "print(f\"  â€¢ GFLOPs: 8.1\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING STATUS: COMPLETE âœ“\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nThe model is ready for inference!\")\n",
    "print(f\"\\nTo use the model for predictions:\")\n",
    "print(f\"  from ultralytics import YOLO\")\n",
    "print(f\"  model = YOLO('{model_path}')\")\n",
    "print(f\"  results = model.predict(source='path/to/image')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38379c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, accuracy_score\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# First check if we have required modules and paths\n",
    "try:\n",
    "    # Try to access yolo_dataset_path - if it fails, run initialization code\n",
    "    _ = yolo_dataset_path\n",
    "except NameError:\n",
    "    print(\"âš ï¸  Required variables not found. Initializing base paths...\")\n",
    "    base_path = r\"C:\\Users\\praha\\Downloads\\archive (4)\\innovit_.ipynb\\SBVPI_SIP\"\n",
    "    yolo_dataset_path = os.path.join(base_path, \"yolo_dataset\")\n",
    "    print(f\"Base path set to: {base_path}\")\n",
    "    print(f\"YOLO dataset path: {yolo_dataset_path}\")\n",
    "    print(\"\\nâš ï¸  WARNING: Please run cells 1-6 first to properly train the model.\")\n",
    "    print(\"This cell requires: yolo_dataset_path, val_images, val_masks, and a trained model\")\n",
    "    print(\"\\nProceeding with available data...\\n\")\n",
    "\n",
    "# Prepare labels from masks\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPARING LABELS FROM MASKS...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "val_images_dir = os.path.join(yolo_dataset_path, \"images\", \"val\")\n",
    "val_labels_dir = os.path.join(yolo_dataset_path, \"labels\", \"val\")\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "\n",
    "# Try to create labels from masks if val_masks is available\n",
    "try:\n",
    "    for i, val_image_path in enumerate(val_images):\n",
    "        image_basename = os.path.basename(val_image_path)\n",
    "        label_file = os.path.splitext(image_basename)[0] + '.txt'\n",
    "        label_path = os.path.join(val_labels_dir, label_file)\n",
    "        \n",
    "        if not os.path.exists(label_path) and i < len(val_masks):\n",
    "            mask_path = val_masks[i]\n",
    "            if os.path.exists(mask_path):\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if mask is not None:\n",
    "                    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    if len(contours) > 0:\n",
    "                        with open(label_path, 'w') as f:\n",
    "                            # Handle both 2D and 3D arrays\n",
    "                            if mask.ndim == 3:\n",
    "                                img_h, img_w, _ = mask.shape\n",
    "                            else:\n",
    "                                img_h, img_w = mask.shape\n",
    "                            \n",
    "                            for contour in contours:\n",
    "                                x, y, w, h = cv2.boundingRect(contour)\n",
    "                                x_center = (x + w/2) / img_w\n",
    "                                y_center = (y + h/2) / img_h\n",
    "                                box_w = w / img_w\n",
    "                                box_h = h / img_h\n",
    "                                f.write(f\"0 {x_center:.6f} {y_center:.6f} {box_w:.6f} {box_h:.6f}\\n\")\n",
    "                    else:\n",
    "                        open(label_path, 'a').close()\n",
    "except NameError:\n",
    "    print(\"âš ï¸  val_masks not available. Skipping mask-based label creation.\")\n",
    "\n",
    "print(\"âœ“ Labels prepared\")\n",
    "\n",
    "# Run validation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING VALIDATION AND COMPUTING METRICS...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_scores = []\n",
    "\n",
    "val_image_files = sorted([f for f in os.listdir(val_images_dir) if f.endswith(('.jpg', '.png'))])\n",
    "\n",
    "if len(val_image_files) == 0:\n",
    "    print(\"âš ï¸  No validation images found!\")\n",
    "else:\n",
    "    print(f\"\\nProcessing {len(val_image_files)} validation images...\")\n",
    "    \n",
    "    # Check if model is available\n",
    "    try:\n",
    "        test_model = model\n",
    "    except NameError:\n",
    "        print(\"âš ï¸  Model not found. Please run cells 1-6 first!\")\n",
    "        raise\n",
    "    \n",
    "    for img_file in tqdm(val_image_files, desc=\"Validation\"):\n",
    "        img_path = os.path.join(val_images_dir, img_file)\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        label_path = os.path.join(val_labels_dir, label_file)\n",
    "        has_object = 1 if os.path.exists(label_path) and os.path.getsize(label_path) > 0 else 0\n",
    "        y_true.append(has_object)\n",
    "        \n",
    "        try:\n",
    "            results = model.predict(img_path, verbose=False)\n",
    "            detections = results[0].boxes\n",
    "            has_detection = 1 if len(detections) > 0 else 0\n",
    "            y_pred.append(has_detection)\n",
    "            confidence = float(detections.conf.max()) if len(detections) > 0 else 0.0\n",
    "            y_scores.append(confidence)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "            y_pred.append(0)\n",
    "            y_scores.append(0.0)\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_scores = np.array(y_scores)\n",
    "\n",
    "    if len(y_true) > 0:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "        if cm.size == 1:\n",
    "            cm = np.array([[cm[0, 0], 0], [0, 0]]) if cm[0, 0] > 0 else np.array([[0, 0], [0, cm[0, 0]]])\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, labels=[0, 1], average='binary', zero_division=0)\n",
    "\n",
    "        print(f\"\\nâœ“ Validation complete!\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "        # Create visualizations\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CREATING EVALUATION VISUALIZATIONS...\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('YOLOv8 Validation Metrics & Evaluation', fontsize=18, fontweight='bold')\n",
    "\n",
    "        # Plot 1: Confusion Matrix\n",
    "        ax = axes[0, 0]\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                    xticklabels=['No Object', 'Object'],\n",
    "                    yticklabels=['No Object', 'Object'],\n",
    "                    cbar_kws={'label': 'Count'})\n",
    "        ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('True Label', fontsize=12)\n",
    "        ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        metrics_text = f\"Accuracy: {accuracy:.3f}\\nPrecision: {precision:.3f}\\nRecall: {recall:.3f}\\nF1-Score: {f1:.3f}\"\n",
    "        ax.text(2.5, 0.5, metrics_text, fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "        # Plot 2: ROC Curve\n",
    "        ax = axes[0, 1]\n",
    "        if len(set(y_true)) > 1:\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            ax.plot(fpr, tpr, color='darkorange', lw=2.5, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "        ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "        ax.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc=\"lower right\", fontsize=11)\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        # Plot 3: Metrics Bar Chart\n",
    "        ax = axes[1, 0]\n",
    "        metrics_dict = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-Score': f1}\n",
    "        colors_bar = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "        bars = ax.bar(metrics_dict.keys(), metrics_dict.values(), color=colors_bar, edgecolor='black', linewidth=1.5)\n",
    "        ax.set_ylabel('Score', fontsize=12)\n",
    "        ax.set_title('Classification Metrics', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylim([0, 1.1])\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        for bar, val in zip(bars, metrics_dict.values()):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{val:.3f}',\n",
    "                    ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "        # Plot 4: Metrics Summary\n",
    "        ax = axes[1, 1]\n",
    "        ax.axis('off')\n",
    "        metrics_summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘    DETAILED EVALUATION METRICS         â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ CONFUSION MATRIX:                      â•‘\n",
    "â•‘   True Negatives (TN):  {tn:>3d}           â•‘\n",
    "â•‘   False Positives (FP): {fp:>3d}           â•‘\n",
    "â•‘   False Negatives (FN): {fn:>3d}           â•‘\n",
    "â•‘   True Positives (TP):  {tp:>3d}           â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ CLASSIFICATION METRICS:                â•‘\n",
    "â•‘   Accuracy:   {accuracy:.4f}              â•‘\n",
    "â•‘   Precision:  {precision:.4f}              â•‘\n",
    "â•‘   Recall:     {recall:.4f}              â•‘\n",
    "â•‘   F1-Score:   {f1:.4f}              â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘ DETECTION PERFORMANCE:                 â•‘\n",
    "â•‘   Total Samples:      {len(y_true):>3d}           â•‘\n",
    "â•‘   Correctly Detected: {(tp + tn):>3d}           â•‘\n",
    "â•‘   Incorrectly Detected: {(fp + fn):>3d}           â•‘\n",
    "â•‘   Detection Rate: {((tp + tn)/len(y_true)*100) if len(y_true) > 0 else 0:.2f}%         â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "        ax.text(0.05, 0.5, metrics_summary, fontsize=10, family='monospace',\n",
    "                verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3, pad=1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(base_path, 'evaluation_metrics.png'), dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ“ Evaluation metrics plot saved\")\n",
    "        plt.show()\n",
    "\n",
    "        # Accuracy validation (75% threshold)\n",
    "        accuracy_threshold = 0.75\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MODEL ACCURACY VALIDATION\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Required Accuracy Threshold: {accuracy_threshold*100:.1f}%\")\n",
    "        print(f\"Model Accuracy Achieved:     {accuracy*100:.2f}%\")\n",
    "        \n",
    "        if accuracy >= accuracy_threshold:\n",
    "            print(f\"\\nâœ… PASS - Model meets accuracy requirement!\")\n",
    "            print(f\"   Accuracy is {(accuracy - accuracy_threshold)*100:.2f}% above the 75% threshold\")\n",
    "        else:\n",
    "            accuracy_gap = (accuracy_threshold - accuracy) * 100\n",
    "            print(f\"\\nâŒ FAIL - Model does not meet accuracy requirement!\")\n",
    "            print(f\"   Model needs {accuracy_gap:.2f}% more accuracy to reach 75% threshold\")\n",
    "            print(f\"   Current accuracy: {accuracy*100:.2f}% (Target: 75%)\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"âœ“ EVALUATION COMPLETE!\")\n",
    "        print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING ADVANCED PERFORMANCE VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create comprehensive dashboard\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# Title\n",
    "fig.suptitle('YOLOv8 Model - Advanced Performance Analysis Dashboard', \n",
    "             fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "# ===== ROC Curve (Large - Top Left) =====\n",
    "ax_roc = fig.add_subplot(gs[0:2, 0:2])\n",
    "if len(set(y_true)) > 1:\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    ax_roc.plot(fpr, tpr, color='#2E86AB', lw=3, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "    ax_roc.fill_between(fpr, tpr, alpha=0.2, color='#2E86AB')\n",
    "else:\n",
    "    fpr, tpr = [0, 1], [0, 1]\n",
    "    roc_auc = 0\n",
    "    ax_roc.plot(fpr, tpr, color='#2E86AB', lw=3, label='ROC Curve (all same class)')\n",
    "\n",
    "# Random classifier line\n",
    "ax_roc.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.5)')\n",
    "ax_roc.set_xlim([0.0, 1.0])\n",
    "ax_roc.set_ylim([0.0, 1.05])\n",
    "ax_roc.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax_roc.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax_roc.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "ax_roc.legend(loc=\"lower right\", fontsize=11)\n",
    "ax_roc.grid(True, alpha=0.3)\n",
    "\n",
    "# ===== Precision-Recall Curve (Top Right) =====\n",
    "ax_pr = fig.add_subplot(gs[0, 2])\n",
    "if len(set(y_true)) > 1:\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_true, y_scores)\n",
    "    pr_auc = auc(recall_vals, precision_vals)\n",
    "    ax_pr.plot(recall_vals, precision_vals, color='#A23B72', lw=2.5, marker='o', markersize=5,\n",
    "              label=f'PR Curve (AUC = {pr_auc:.4f})')\n",
    "    ax_pr.fill_between(recall_vals, precision_vals, alpha=0.2, color='#A23B72')\n",
    "    ax_pr.set_xlim([0.0, 1.05])\n",
    "    ax_pr.set_ylim([0.0, 1.05])\n",
    "else:\n",
    "    ax_pr.text(0.5, 0.5, 'Single class\\nNo PR Curve', ha='center', va='center', fontsize=11)\n",
    "\n",
    "ax_pr.set_xlabel('Recall', fontsize=11, fontweight='bold')\n",
    "ax_pr.set_ylabel('Precision', fontsize=11, fontweight='bold')\n",
    "ax_pr.set_title('Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
    "ax_pr.grid(True, alpha=0.3)\n",
    "if len(set(y_true)) > 1:\n",
    "    ax_pr.legend(fontsize=9, loc='best')\n",
    "\n",
    "# ===== Confidence Score Distribution (Middle Right) =====\n",
    "ax_conf = fig.add_subplot(gs[1, 2])\n",
    "# Separate by true class\n",
    "neg_scores = y_scores[y_true == 0]\n",
    "pos_scores = y_scores[y_true == 1]\n",
    "\n",
    "ax_conf.hist(neg_scores, bins=15, alpha=0.6, label=f'No Object (n={len(neg_scores)})', color='#E63946', edgecolor='black')\n",
    "ax_conf.hist(pos_scores, bins=15, alpha=0.6, label=f'Object (n={len(pos_scores)})', color='#06A77D', edgecolor='black')\n",
    "ax_conf.set_xlabel('Confidence Score', fontsize=11, fontweight='bold')\n",
    "ax_conf.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax_conf.set_title('Confidence Distribution', fontsize=12, fontweight='bold')\n",
    "ax_conf.legend(fontsize=9)\n",
    "ax_conf.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# ===== Confusion Matrix Heatmap (Bottom Left) =====\n",
    "ax_cm = fig.add_subplot(gs[2, 0])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn', ax=ax_cm, \n",
    "            xticklabels=['No Object', 'Object'],\n",
    "            yticklabels=['No Object', 'Object'],\n",
    "            cbar_kws={'label': 'Count'}, \n",
    "            annot_kws={'fontsize': 12, 'fontweight': 'bold'})\n",
    "ax_cm.set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "ax_cm.set_ylabel('True Label', fontsize=11, fontweight='bold')\n",
    "ax_cm.set_xlabel('Predicted Label', fontsize=11, fontweight='bold')\n",
    "\n",
    "# ===== Metrics Bar Chart (Bottom Middle) =====\n",
    "ax_metrics = fig.add_subplot(gs[2, 1])\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall_val = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision_val,\n",
    "    'Recall': recall_val,\n",
    "    'Specificity': specificity,\n",
    "    'F1-Score': f1\n",
    "}\n",
    "\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#95E1D3']\n",
    "bars = ax_metrics.barh(list(metrics.keys()), list(metrics.values()), color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax_metrics.set_xlim([0, 1.1])\n",
    "ax_metrics.set_title('Performance Metrics', fontsize=12, fontweight='bold')\n",
    "ax_metrics.set_xlabel('Score', fontsize=11, fontweight='bold')\n",
    "ax_metrics.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "for i, (bar, val) in enumerate(zip(bars, metrics.values())):\n",
    "    ax_metrics.text(val + 0.02, i, f'{val:.4f}', va='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "# ===== Detailed Statistics Summary (Bottom Right) =====\n",
    "ax_stats = fig.add_subplot(gs[2, 2])\n",
    "ax_stats.axis('off')\n",
    "\n",
    "stats_text = f\"\"\"MODEL PERFORMANCE SUMMARY\n",
    "\n",
    "Dataset Statistics:\n",
    "  â€¢ Total Samples: {len(y_true)}\n",
    "  â€¢ Positive Class: {np.sum(y_true)} \n",
    "  â€¢ Negative Class: {len(y_true) - np.sum(y_true)}\n",
    "\n",
    "Confusion Matrix:\n",
    "  â€¢ TP: {tp}  |  FP: {fp}\n",
    "  â€¢ FN: {fn}  |  TN: {tn}\n",
    "\n",
    "Key Metrics:\n",
    "  â€¢ Accuracy:    {accuracy:.4f}\n",
    "  â€¢ Precision:   {precision_val:.4f}\n",
    "  â€¢ Recall:      {recall_val:.4f}\n",
    "  â€¢ Specificity: {specificity:.4f}\n",
    "  â€¢ F1-Score:    {f1:.4f}\n",
    "  â€¢ ROC-AUC:     {roc_auc:.4f}\n",
    "\n",
    "Classification Rate:\n",
    "  â€¢ Correct:     {(tp + tn):>3d} ({((tp + tn)/len(y_true)*100):>5.1f}%)\n",
    "  â€¢ Incorrect:   {(fp + fn):>3d} ({((fp + fn)/len(y_true)*100):>5.1f}%)\n",
    "\"\"\"\n",
    "\n",
    "ax_stats.text(0.05, 0.95, stats_text, transform=ax_stats.transAxes,\n",
    "             fontsize=9, verticalalignment='top', family='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.4, pad=1))\n",
    "\n",
    "plt.savefig(os.path.join(base_path, 'roc_and_performance_dashboard.png'), dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nâœ“ Advanced performance dashboard saved to: {os.path.join(base_path, 'roc_and_performance_dashboard.png')}\")\n",
    "plt.show()\n",
    "\n",
    "# Additional: Create individual ROC curve plot\n",
    "fig2, ax = plt.subplots(figsize=(10, 8))\n",
    "if len(set(y_true)) > 1:\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    ax.plot(fpr, tpr, color='#2E86AB', lw=3, marker='o', markersize=8, \n",
    "           label=f'ROC Curve (AUC = {roc_auc:.4f})', markerfacecolor='#FFA5A5')\n",
    "    ax.fill_between(fpr, tpr, alpha=0.15, color='#2E86AB')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2.5, label='Random Classifier (AUC = 0.5)')\n",
    "ax.set_xlim([-0.02, 1.02])\n",
    "ax.set_ylim([-0.02, 1.02])\n",
    "ax.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate (Sensitivity/Recall)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Receiver Operating Characteristic (ROC) Curve\\nYOLOv8 Object Detection Model', \n",
    "            fontsize=15, fontweight='bold', pad=20)\n",
    "ax.legend(loc=\"lower right\", fontsize=12, framealpha=0.9)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(base_path, 'roc_curve_detailed.png'), dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ“ Detailed ROC curve saved to: {os.path.join(base_path, 'roc_curve_detailed.png')}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ ALL VISUALIZATIONS CREATED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nFiles saved:\")\n",
    "print(f\"  1. {os.path.join(base_path, 'evaluation_metrics.png')}\")\n",
    "print(f\"  2. {os.path.join(base_path, 'roc_and_performance_dashboard.png')}\")\n",
    "print(f\"  3. {os.path.join(base_path, 'roc_curve_detailed.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad623804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Visualize training results\n",
    "print(\"Creating visualization plots...\")\n",
    "\n",
    "# Create figure for results summary\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('YOLOv11 Training Summary', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Dataset statistics\n",
    "ax = axes[0, 0]\n",
    "dataset_info = {\n",
    "    'Original Images': len(image_files),\n",
    "    'Synthetic Images': synthetic_count,\n",
    "    'Training Set': len(train_images),\n",
    "    'Validation Set': len(val_images)\n",
    "}\n",
    "bars = ax.bar(dataset_info.keys(), dataset_info.values(), color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "ax.set_ylabel('Count', fontsize=11)\n",
    "ax.set_title('Dataset Composition', fontsize=12, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Plot 2: Model architecture info\n",
    "ax = axes[0, 1]\n",
    "ax.axis('off')\n",
    "model_info = f\"\"\"\n",
    "YOLOv11 Configuration:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Model: YOLOv11n (Nano)\n",
    "Epochs: 50\n",
    "Batch Size: 16\n",
    "Image Size: 416x416\n",
    "Early Stopping: Yes (patience=10)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Data Augmentation Applied:\n",
    "âœ“ Rotation âœ“ Flip\n",
    "âœ“ Gaussian Noise âœ“ Blur\n",
    "âœ“ Brightness/Contrast\n",
    "âœ“ Elastic Transform\n",
    "âœ“ ShiftScale âœ“ Affine\n",
    "âœ“ CoarseDropout\n",
    "\"\"\"\n",
    "ax.text(0.1, 0.5, model_info, fontsize=10, family='monospace',\n",
    "        verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Plot 3: Augmentation techniques used\n",
    "ax = axes[1, 0]\n",
    "augmentations = ['Rotation', 'Flip', 'Noise', 'Blur', 'Brightness', 'Elastic', 'ShiftScale', 'Dropou t']\n",
    "aug_probs = [0.7, 0.5, 0.3, 0.3, 0.5, 0.3, 0.5, 0.3]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(augmentations)))\n",
    "bars = ax.barh(augmentations, aug_probs, color=colors)\n",
    "ax.set_xlabel('Probability', fontsize=11)\n",
    "ax.set_title('Data Augmentation Probabilities', fontsize=12, fontweight='bold')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 4: Results directory info\n",
    "ax = axes[1, 1]\n",
    "ax.axis('off')\n",
    "results_info = f\"\"\"\n",
    "Training Results Location:\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "ğŸ“ runs/detect/yoloV11_training/\n",
    "  â”œâ”€â”€ weights/\n",
    "  â”‚   â”œâ”€â”€ best.pt âœ“\n",
    "  â”‚   â””â”€â”€ last.pt âœ“\n",
    "  â”œâ”€â”€ results.csv\n",
    "  â”œâ”€â”€ confusion_matrix.png\n",
    "  â”œâ”€â”€ F1_curve.png\n",
    "  â”œâ”€â”€ P_curve.png\n",
    "  â”œâ”€â”€ R_curve.png\n",
    "  â””â”€â”€ PR_curve.png\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "Dataset Path:\n",
    "ğŸ“ {yolo_dataset_path}/\n",
    "  â”œâ”€â”€ images/\n",
    "  â”‚   â”œâ”€â”€ train/\n",
    "  â”‚   â””â”€â”€ val/\n",
    "  â””â”€â”€ labels/\n",
    "      â”œâ”€â”€ train/\n",
    "      â””â”€â”€ val/\n",
    "\"\"\"\n",
    "ax.text(0.05, 0.5, results_info, fontsize=9, family='monospace',\n",
    "        verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(base_path, 'training_summary.png'), dpi=150, bbox_inches='tight')\n",
    "print(\"âœ“ Summary plot saved to:\", os.path.join(base_path, 'training_summary.png'))\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Review training results in: runs/detect/yoloV11_training/\")\n",
    "print(\"2. Use best.pt for inference on new images\")\n",
    "print(\"3. Fine-tune hyperparameters if needed\")\n",
    "print(f\"\\nğŸ“Š Original Images: {len(image_files)}\")\n",
    "print(f\"ğŸ”„ Synthetic Images Generated: {synthetic_count}\")\n",
    "print(f\"ğŸ“ˆ Total Training Samples: {len(train_images)}\")\n",
    "print(f\"âœ… Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Inference helper function (use after model training)\n",
    "def run_inference_on_images(image_folder, model_path=None, confidence=0.25):\n",
    "    \"\"\"\n",
    "    Run inference on a folder of images using the trained model.\n",
    "    \n",
    "    Args:\n",
    "        image_folder: Path to folder containing images\n",
    "        model_path: Path to trained model (best.pt or last.pt)\n",
    "        confidence: Confidence threshold for detections\n",
    "    \"\"\"\n",
    "    if model_path is None:\n",
    "        model_path = 'runs/detect/yoloV11_training/weights/best.pt'\n",
    "    \n",
    "    print(f\"\\nLoading model from: {model_path}\")\n",
    "    inference_model = YOLO(model_path)\n",
    "    \n",
    "    print(f\"Running inference on images in: {image_folder}\")\n",
    "    results = inference_model.predict(\n",
    "        source=image_folder,\n",
    "        conf=confidence,\n",
    "        save=True,\n",
    "        device=0 if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Inference complete! Results saved to: runs/detect/predict/\")\n",
    "    return results\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# results = run_inference_on_images(image_folder='path/to/test/images')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INFERENCE FUNCTION READY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTo run inference on new images, use:\")\n",
    "print(\"  results = run_inference_on_images('path/to/test/images')\")\n",
    "print(\"\\nThe trained model is available at:\")\n",
    "print(\"  runs/detect/yoloV11_training/weights/best.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
